{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d771aeb6-9412-4c46-b256-206ccdc5fe5c",
   "metadata": {},
   "source": [
    "# 1. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0852e45-58de-48da-a034-f966eb71bee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.vgg import vgg11, vgg13, vgg16, vgg19 \n",
    "from torch.ao.quantization import QuantStub, DeQuantStub\n",
    "from utils.utils import calculate_op\n",
    "from utils.train_utils import create_dataset,compute_accuracy\n",
    "from utils.pca import extract_primary_layers\n",
    "from utils.quantization import quantize_model, print_size_of_model\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "_, _, trainloader, testloader = create_dataset(dataset = \"cifar10\", data_root = \"./data\", batch_size = 2048, num_workers = 2)\n",
    "\n",
    "weight_path = \"best_model_vgg11.pt\"\n",
    "\n",
    "model = vgg11()\n",
    "# model.to(torch.device('cpu'))\n",
    "model.load_state_dict(torch.load(weight_path, map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "ori_model_size = print_size_of_model(model)\n",
    "\n",
    "ori_test_acc = compute_accuracy(testloader, model, \"cpu\")\n",
    "ori_macs, ori_params = calculate_op(x, model)\n",
    "\n",
    "\n",
    "#modify based on vgg model, this return node is specified for vgg11\n",
    "return_nodes = {\n",
    "    \"features.1\": \"layer1\",\n",
    "    \"features.4\": \"layer2\",\n",
    "    \"features.7\": \"layer3\",\n",
    "    \"features.9\": \"layer4\",\n",
    "    \"features.12\": \"layer5\",\n",
    "    \"features.14\": \"layer6\",\n",
    "    \"features.17\": \"layer7\",\n",
    "    \"features.19\": \"layer8\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e24ce-40e9-4923-a95e-7463b4ee4e4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. select primary layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa509e9-3b4e-4a6e-8c21-68a891eb9b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.1 analysis result\n",
      "need at least 37 filter(s) out of 64 components to exceed threshold. So 57.81% of filters needed minimum to exceed threshold\n",
      "features.4 analysis result\n",
      "need at least 49 filter(s) out of 128 components to exceed threshold. So 38.28% of filters needed minimum to exceed threshold\n",
      "features.7 analysis result\n",
      "need at least 87 filter(s) out of 256 components to exceed threshold. So 33.98% of filters needed minimum to exceed threshold\n",
      "features.9 analysis result\n",
      "need at least 83 filter(s) out of 256 components to exceed threshold. So 32.42% of filters needed minimum to exceed threshold\n",
      "features.12 analysis result\n",
      "need at least 111 filter(s) out of 512 components to exceed threshold. So 21.68% of filters needed minimum to exceed threshold\n",
      "features.14 analysis result\n",
      "need at least 51 filter(s) out of 512 components to exceed threshold. So 9.96% of filters needed minimum to exceed threshold\n",
      "features.17 analysis result\n",
      "need at least 68 filter(s) out of 512 components to exceed threshold. So 13.28% of filters needed minimum to exceed threshold\n",
      "features.19 analysis result\n",
      "need at least 11 filter(s) out of 512 components to exceed threshold. So 2.15% of filters needed minimum to exceed threshold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('features.1', 0.578125), ('features.4', 0.3828125)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_primary_layers = 2\n",
    "\n",
    "primary_layers = extract_primary_layers(x, model, return_nodes, threshold = 0.99, num_layers = num_primary_layers, verbose = True)\n",
    "primary_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad2890-33ef-4398-94bb-6ebde9bcdcce",
   "metadata": {},
   "source": [
    "# 3. quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8696e1a-3be2-4a2e-9f65-b600c84b6adc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "      (1): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.04875442758202553, zero_point=0, padding=(1, 1))\n",
       "      (2): DeQuantize()\n",
       "    )\n",
       "    (1): Identity()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Sequential(\n",
       "      (0): Quantize(scale=tensor([0.0536]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "      (1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.06528432667255402, zero_point=0, padding=(1, 1))\n",
       "      (2): DeQuantize()\n",
       "    )\n",
       "    (4): Identity()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantize_model(model, primary_layers, trainloader, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550de5d-5a7b-4c66-a0b2-73d5a27571ea",
   "metadata": {},
   "source": [
    "# 4. Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc6848-0da0-4eb9-b24c-81b2d01d7d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(testloader, model, \"cpu\")\n",
    "q_macs, q_params = calculate_op(x, model)\n",
    "\n",
    "\n",
    "quant_model_size = print_size_of_model(model)\n",
    "\n",
    "print(\"test accuracy is changed from {:.04f} to {:.04f}\".format(ori_test_acc, test_acc))\n",
    "print(\"Number of parameters changed from {:.04f}M to {:.04f}M\".format(ori_params/1e6, q_params/1e6))\n",
    "print(\"Size of model changed from {:.04f}MB to {:.04f}MB\".format(ori_model_size/1e6, quant_model_size/1e6))\n",
    "print(\"MACs changed from {:.02f}G to {:.02f}G\".format(ori_macs/1e9, q_macs/1e9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
